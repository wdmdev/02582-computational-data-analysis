{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To embed plots in the notebooks\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np # numpy library\n",
    "import scipy.io\n",
    "from scipy.spatial import distance # load distance function\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import preprocessing as preproc # load preprocessing function\n",
    "\n",
    "# seaborn can be used to \"prettify\" default matplotlib plots by importing and setting as default\n",
    "import seaborn as sns\n",
    "sns.set() # Set searborn as default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Use the receiver operator curve (ROC) and determine specificity and sensitivity:\n",
    "> (a) Make a function `[sens, spec] = roc_data( y, y_true, cut)` that takes as input the estimated response y, the true response ytrue and the cut off value cut, and outputs the sensitivity and specificity.\n",
    "*Hint: compute TP, TN, FP and FN. From there, sensitivity and specificity is easily computed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_data(y, y_true, cut):\n",
    "    \"\"\"Calculate the sensitivity and specificity of a given class \n",
    "\n",
    "    Keyword arguments:\n",
    "    y_hat [ndarray] -- The estimated probability for each observation belonging to the given class\n",
    "    y_true [ndarray]-- The actual class label for the observations\n",
    "    cut    float -- The cutoff at which the sensitivity and specificity are to be calculated\n",
    "    \n",
    "    Return:\n",
    "    the sensitivity[float] and specificity[float] at each of the cutoff value.\n",
    "    \"\"\"\n",
    "\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">(b) Run the blocks below which use your `roc_data`. The output plot illustrates the data for the next exercise. Try to adjust the cut off value for the classification rule, which is also plotted in the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_data():\n",
    "    n1 = 20\n",
    "    n2 = 100\n",
    "    n = n1 + n2\n",
    "    mu1 = np.array([2, 3])\n",
    "    mu2 = np.array([3, 5])\n",
    "    SIGMA1 = np.array([[1, 1.5], [1.5, 3]])\n",
    "    SIGMA2 = np.array([[2, 1], [1, 1]])\n",
    "\n",
    "    r1 = np.random.multivariate_normal(mu1,SIGMA1,n1)\n",
    "    r2 = np.random.multivariate_normal(mu2,SIGMA2,n2)\n",
    "    X = np.concatenate((r1, r2), axis=0)\n",
    "    y = np.concatenate((np.ones((n1)), -np.ones((n2))), axis=0)\n",
    "\n",
    "    return X, y, r1, r2, n1, n2, n\n",
    "\n",
    "def abline(ax, slope, intercept,linetype):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    x_vals = np.array(ax.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    ax.plot(x_vals, y_vals, linetype)\n",
    "\n",
    "def plotData(ax, lda, data,cut):\n",
    "    _, _, r1, r2, _, _, _ = data\n",
    "\n",
    "    ax.plot(r1[:,0],r1[:,1],'r+',label='Positive class')\n",
    "    ax.plot(r2[:,0],r2[:,1],'bx',label='Negative class')\n",
    "    abline(ax,-lda.coef_[0][0]/lda.coef_[0][1], -lda.intercept_[0]/lda.coef_[0][1],'-g')\n",
    "    abline(ax,-lda.coef_[0][0]/lda.coef_[0][1], -(lda.intercept_[0]-cut)/lda.coef_[0][1],'-k')\n",
    "    ax.set_title('Observations')\n",
    "    ax.set_xlabel('x_1')\n",
    "    ax.set_ylabel('x_2')\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "def plotROC(ax,lda,data,cut):\n",
    "    X, y, _, _, _, _, _ = data\n",
    "    \n",
    "    y_score = lda.decision_function(X)\n",
    "    fpr, tpr, _ = roc_curve(y, y_score)\n",
    "    \n",
    "    y_pred = lda.decision_function(X)\n",
    "    sens, spec = roc_data(y_pred, y, cut)\n",
    "    \n",
    "    lw = 2\n",
    "    ax.plot(fpr, tpr, color='darkorange',lw=lw)\n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    ax.plot(1-spec, sens,'*k')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "\n",
    "def calcConfusionMatrix(lda,data,cut):\n",
    "    X, y, _, _, _, _, _ = data\n",
    "    \n",
    "    f = X@lda.coef_[0] + lda.intercept_[0] - cut\n",
    "    tp = np.sum((f > 0) & (y == 1));\n",
    "    tn = np.sum((f < 0) & (y == -1));\n",
    "    fp = np.sum((f > 0) & (y == -1));\n",
    "    fn = np.sum((f < 0) & (y == 1));\n",
    "    \n",
    "    return ConfusionMatrixDisplay(np.array([[tn, fp],[fn, tp]])), tp/(tp+fn),  tn/(tn+fp), tp/(tp+fp), tp/(tp+fp)\n",
    "\n",
    "data = init_data()\n",
    "X, y, _, _, _, _, _ = data\n",
    "lda = LinearDiscriminantAnalysis().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 0\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "plotData(ax[0], lda, data, value)\n",
    "plotROC(ax[1],lda,data, value)\n",
    "disp, sens, spec, PPV, NPV = calcConfusionMatrix(lda, data, value)\n",
    "disp.plot()\n",
    "print(\"The sensitivity is {}\".format(sens))\n",
    "print(\"The specificity is {}\".format(spec))\n",
    "print(\"The precision is {}\".format(PPV))\n",
    "print(\"The Negative Predictive Value is {}\".format(NPV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">(c) Assume you are developing a mammography system for General Electrics, and that the GUI is showing the two features you have extracted to find suspicious image regions. GE has ordered the system to have a sensitivity of 95% to make sure very few lesions go undetected. Discuss this solution with your mates. What are you sacrificing to get such a sensitive system? Which sensitivity would you recommend based on the given data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
