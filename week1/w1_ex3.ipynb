{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To embed plots in the notebooks\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np # numpy library\n",
    "import scipy . linalg as lng # linear algebra from scipy library\n",
    "from scipy . spatial import distance # load distance function\n",
    "from sklearn import preprocessing as preproc # load preprocessing function\n",
    "\n",
    "# seaborn can be used to \"prettify\" default matplotlib plots by importing and setting as default\n",
    "import seaborn as sns\n",
    "sns.set() # Set searborn as default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetPath = './DiabetesDataNormalized.txt'\n",
    "T = np.loadtxt(diabetPath, delimiter = ' ', skiprows = 1)\n",
    "y = T[:, 10]\n",
    "X = T[:,:10]\n",
    "\n",
    "# Get number of observations (n) and number of independent variables (p)\n",
    "[n, p] = np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Solve the Rigde regression problem and examine Bias and Variance for Ridge:\n",
    "\n",
    "> (a) Derive (using pen and paper) the ridge regression solution by, as you would when minimizing any differentiable analytical function, differentiating $∥{\\bf y} − {\\bf X}β∥ + ∥β∥_2$ with respect to $β$, setting to zero and solving for $β$. That is, solve\n",
    "$\\frac{∂}{∂β} [∥y−Xβ∥_2^2+λ∥β∥_2^2]= 0$ for $β$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (b) Compute ridge-regression solutions for the diabetes data set for 100 values of the regularization parameter in the range $10^{−4}$ to $10^3$. Plot the solutions as a function of this parameter. In the next lecture you will learn how to choose a single parameter value which suits the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that computes the betas in ridge regression analytically\n",
    "# given the design matrix, lambdas, number of independent variables\n",
    "# and dependent values\n",
    "def ridgeMulti(X, _lambda, p, y):\n",
    "    \n",
    "    return betas\n",
    "\n",
    "\n",
    "\n",
    "# make list of lambda values. \n",
    "\n",
    "# run ridge for all lambda values\n",
    "\n",
    "# plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the parameter estimates change when the regularization parameter increase?\n",
    "\n",
    "What does this mean in terms of the bias of the model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (c) Change the experiment in exercise 2 to investigate bias and variance for ridge regression instead of OLS. Can you lower the variance without introducing too much bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate the experiment from the last exercise\n",
    "# you can reuse the code with some edits, and do similar plots to investigate\n",
    "# the bias and variance of ridge\n",
    "\n",
    "def estimate_betas(X, beta_true, sigma, _lambda):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters:\n",
    "    X (nXp matrix): feature matrix used for simulation\n",
    "    true_betas (array): array of ture betas\n",
    "    sigma (float): The noise level in the simulation\n",
    "    _lambda (float): The trade-off parameter for ridge regression\n",
    "\n",
    "    Returns:\n",
    "    beta: the estimated betas\n",
    "\n",
    "   \"\"\"\n",
    "    \n",
    "    \n",
    "    return beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define true betas, n and p, and sigma\n",
    "\n",
    "# Create a feature matrix either using np.random.normal or np.rand.randn\n",
    "\n",
    "m = 100 # number of experiments\n",
    "betas = np.zeros((p, m)) # all variable estimates\n",
    "# call the method you just created 100 times and save the estimated betas\n",
    "\n",
    "# Investigate the mean and variance of the betas that you have estimated from experiments with different noise levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens with the bias and variance as the regularization parameter increase?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
